{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data\n",
    "rmp = pd.read_csv(\"rmf-with-gender.csv\")\n",
    "\n",
    "#Select revelant columns\n",
    "rmp = rmp[['Overall_Quality', 'Comment', 'Prof_Gender']]\n",
    "\n",
    "#Drop rows with missing values\n",
    "rmp = rmp.dropna()\n",
    "\n",
    "#The mean rating is roughly 3.6, so we'll call everyone who received a rating >= 3 satisfactory\n",
    "satisfactory = [\"yes\" if i >= 3 else \"no\" for i in rmp[\"Overall_Quality\"]]\n",
    "rmp[\"Satisfactory\"] = satisfactory\n",
    "rmp = rmp.drop(\"Overall_Quality\", axis=1)\n",
    "\n",
    "#Remove gender\n",
    "tokens = [word_tokenize(i) for i in rmp[\"Comment\"]]\n",
    "gender_pronouns = [\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"man\", \"woman\", \"himself\", \"herself\"]\n",
    "no_gender = [[i for i in list if i not in gender_pronouns] for list in tokens]\n",
    "cleanText = [\" \".join(i) for i in no_gender] \n",
    "rmp[\"Comment\"] = cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics \n",
    "\n",
    "#Sample size \n",
    "N = len(rmp)\n",
    "\n",
    "#Gender distribution \n",
    "num_f = len(rmp[rmp[\"Prof_Gender\"] == \"F\"]) \n",
    "prop_f = num_f / N #sample is 38% female\n",
    "sat_f = len(rmp[(rmp[\"Prof_Gender\"]==\"F\") & (rmp[\"Satisfactory\"]==\"yes\")])\n",
    "unsat_f = len(rmp[(rmp[\"Prof_Gender\"]==\"F\") & (rmp[\"Satisfactory\"]==\"no\")])\n",
    "\n",
    "num_m = len(rmp[rmp[\"Prof_Gender\"] == \"M\"]) \n",
    "prop_m = num_m / N #sample is 62% male\n",
    "sat_m = len(rmp[(rmp[\"Prof_Gender\"]==\"M\") & (rmp[\"Satisfactory\"]==\"yes\")])\n",
    "unsat_m = len(rmp[(rmp[\"Prof_Gender\"]==\"M\") & (rmp[\"Satisfactory\"]==\"no\")])\n",
    "\n",
    "#Chi-square test of independence \n",
    "men_women = np.array([[sat_m, unsat_m],[sat_f, unsat_f]])\n",
    "chi_square = scipy.stats.chi2_contingency(men_women)\n",
    "p_value = chi_square[1] #Reject null--gender and rating are not independent. P is essentially 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Track gender\n",
    "track_gender = np.arange(0, N, 1)\n",
    "rmp[\"Track_Gender\"] = track_gender\n",
    "gender_match = rmp[[\"Track_Gender\",\"Prof_Gender\"]]\n",
    "\n",
    "#Drop gender from training data\n",
    "rmp = rmp.drop(\"Prof_Gender\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(rmp[\"Comment\"], rmp[[\"Satisfactory\", \"Track_Gender\"]], test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize \n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the classifier \n",
    "#I'm choosing to use a logistic classifier because in a previous exercise, it was the most accurate\n",
    "clf = LogisticRegression().fit(X_train_tfidf, yTrain[\"Satisfactory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict outcomes\n",
    "X_new_counts = count_vect.transform(XTest)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression()),])\n",
    "\n",
    "text_clf.fit(XTrain, yTrain[\"Satisfactory\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79903829384358571"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the classifier\n",
    "predicted = text_clf.predict(XTest)\n",
    "np.mean(predicted==np.array(yTest[\"Satisfactory\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the gender bias of of the classifier \n",
    "gender_bias = Table.from_df(yTest)\n",
    "gender_match = Table.from_df(gender_match)\n",
    "\n",
    "gender_bias = gender_bias.relabeled(\"Satisfactory\", \"Actual\")\n",
    "gender_bias = gender_bias.with_column (\"Predicted\", predicted )\n",
    "gender_bias = gender_bias.join(\"Track_Gender\", gender_match, \"Track_Gender\").drop(\"Track_Gender\")\n",
    "\n",
    "#Select random samples of F and M professors to get equivalent gender distribution\n",
    "sample_F = gender_bias.where(\"Prof_Gender\", \"F\").sample(10000)\n",
    "sample_M = gender_bias.where(\"Prof_Gender\", \"M\").sample(10000)\n",
    "gender_50_50 = sample_M.append(sample_F)\n",
    "\n",
    "#Gender and quality distributions\n",
    "sat_F = gender_50_50.where(\"Prof_Gender\", \"F\").where(\"Predicted\", \"yes\").num_rows\n",
    "unsat_F = gender_50_50.where(\"Prof_Gender\", \"F\").where(\"Predicted\", \"no\").num_rows\n",
    "\n",
    "sat_M = gender_50_50.where(\"Prof_Gender\", \"M\").where(\"Predicted\", \"yes\").num_rows\n",
    "unsat_M = gender_50_50.where(\"Prof_Gender\", \"M\").where(\"Predicted\", \"no\").num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-square test of independence \n",
    "chi_square_50_50 = np.array([[sat_M, sat_F],[unsat_M, unsat_F]])\n",
    "chi_square_stat = scipy.stats.chi2_contingency(chi_square_50_50)\n",
    "p_value_50_50 = chi_square_stat[1] #Reject null--gender and rating are not independent at alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.570776187328\n",
      "proportion of satisfactory female teachers: 0.9248\n",
      "proportion of satisfactory male teachers: 0.927\n"
     ]
    }
   ],
   "source": [
    "#Calibration: same likelihood of satisfactory/unsatisfactory for men and women\n",
    "print(\"p-value: \" + str(p_value_50_50))\n",
    "print(\"proportion of satisfactory female teachers: \" + str(sat_F/10000))\n",
    "print(\"proportion of satisfactory male teachers: \" + str(sat_M/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positve error rate of female teachers: 0.0306\n",
      "false negative error rate of female teachers: 0.1779\n",
      "false positve error rate of male teachers: 0.0299\n",
      "false negative error rate of male teachers: 0.1683\n"
     ]
    }
   ],
   "source": [
    "#Error rate balance: false positive and false negative error rates are equal across groups\n",
    "\n",
    "false_pos_m = gender_50_50.where(\"Prof_Gender\", \"M\").where(\"Actual\", \"yes\").where(\"Predicted\", \"no\").num_rows\n",
    "false_neg_m = gender_50_50.where(\"Prof_Gender\", \"M\").where(\"Actual\", \"no\").where(\"Predicted\", \"yes\").num_rows\n",
    "false_pos_rate_m = false_pos_m/10000\n",
    "false_neg_rate_m = false_neg_m/10000\n",
    "\n",
    "false_pos_f = gender_50_50.where(\"Prof_Gender\", \"F\").where(\"Actual\", \"yes\").where(\"Predicted\", \"no\").num_rows\n",
    "false_neg_f = gender_50_50.where(\"Prof_Gender\", \"F\").where(\"Actual\", \"no\").where(\"Predicted\", \"yes\").num_rows\n",
    "false_pos_rate_f = false_pos_f/10000\n",
    "false_neg_rate_f = false_neg_f/10000\n",
    "\n",
    "\n",
    "print(\"false positve error rate of female teachers: \" + str(false_pos_rate_f))\n",
    "print(\"false negative error rate of female teachers: \" + str(false_neg_rate_f))\n",
    "print(\"false positve error rate of male teachers: \" + str(false_pos_rate_m))\n",
    "print(\"false negative error rate of male teachers: \" + str(false_neg_rate_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization\n",
    "\n",
    "#Match rmp universities to DOE list of universities, which contains city information\n",
    "rmp_locations = pd.read_csv(\"rmf-with-gender.csv\")\n",
    "rmp_locations = rmp_locations[[\"School\", \"Overall_Quality\", \"Comment\", \"Prof_Gender\"]]\n",
    "rmp_locations = rmp_locations.dropna()\n",
    "rmp_locations.rename(columns={\"School\": \"Institution_Name\"}, inplace=True)\n",
    "\n",
    "university_roster = pd.read_csv(\"Accreditation_04_2017.csv\")\n",
    "university_roster = university_roster[[\"Institution_Name\", \"Institution_City\", \"Institution_State\", \"Institution_Zip\"]]\n",
    "\n",
    "#Create an array of all unique cities\n",
    "locations = pd.merge(university_roster, rmp_locations, on=\"Institution_Name\", how='inner')\n",
    "locations = locations[\"Institution_City\"]\n",
    "locations = locations.unique()\n",
    "\n",
    "#Plot \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from geopy.geocoders import Nominatim\n",
    "import math\n",
    "import shapefile\n",
    "\n",
    "scale = 5\n",
    "\n",
    "map = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "        projection='lcc',lat_1=32,lat_2=45,lon_0=-95)\n",
    "\n",
    "# load the shapefile, use the name 'states'\n",
    "map.readshapefile(\"cb_2015_us_state_20m\", name='states', drawbounds=True)\n",
    "\n",
    "# Get the location of each city and plot it\n",
    "geolocator = Nominatim()\n",
    "\n",
    "for (city) in locations:\n",
    "    loc = geolocator.geocode(city)\n",
    "    x, y = map(loc.longitude, loc.latitude)\n",
    "    map.plot(x,y,marker='o',color='Red')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
