{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data\n",
    "rmp = pd.read_csv(\"rmf-with-gender.csv\")\n",
    "\n",
    "#Drop rows with missing values\n",
    "rmp = rmp.dropna()\n",
    "\n",
    "#Convert dataframe to table \n",
    "rmp = Table.from_df(rmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics \n",
    "\n",
    "#Sample size \n",
    "N = rmp.num_rows\n",
    "unique_instructors = rmp.group(\"Prof_Name\").num_rows \n",
    "\n",
    "#Gender distribution \n",
    "num_f = sum ([1 for i in rmp.column(\"Prof_Gender\") if i == \"F\"])\n",
    "prop_f = num_f / N\n",
    "\n",
    "num_m = sum ([1 for i in rmp.column(\"Prof_Gender\") if i == \"M\"])\n",
    "prop_m = num_m / N\n",
    "\n",
    "#Rating distribution across gender\n",
    "cross_tab = rmp.group([\"Prof_Gender\", \"Rating_Type\"])\n",
    "cross_tab = cross_tab.with_column(\"Proportion\", cross_tab.column(2)/N).sort(\"Proportion\", descending = True)\n",
    "\n",
    "cross_tab_f = cross_tab.where(\"Prof_Gender\", \"F\").drop(\"Proportion\")\n",
    "cross_tab_f = cross_tab_f.with_column(\"Proportion\", cross_tab_f.column(\"count\")/num_f)\n",
    "\n",
    "cross_tab_m = cross_tab.where(\"Prof_Gender\", \"M\").drop(\"Proportion\")\n",
    "cross_tab_m = cross_tab_m.with_column(\"Proportion\", cross_tab_m.column(\"count\")/num_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing function\n",
    "\n",
    "def clean (text): \n",
    "    from nltk.corpus import stopwords\n",
    "    from string import punctuation\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    stopwords = stopwords.words(\"english\")\n",
    "    punctuation = list(punctuation)\n",
    "    gender_pronouns = [\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"man\", \"woman\", \"himself\", \"herself\"]\n",
    "    \n",
    "    #Tokenize\n",
    "    tokens = [word_tokenize(i) for i in text]\n",
    "    \n",
    "    #Convert all words to lowercase\n",
    "    lower_case = [[i.lower() for i in list] for list in tokens]\n",
    "    \n",
    "    #Remove stop words, punctuation, and gender indicators \n",
    "    no_stopwords = [[i for i in list if i not in stopwords] for list in lower_case]\n",
    "    no_punctuation = [[i for i in list if i not in punctuation] for list in no_stopwords]\n",
    "    no_gender = [[i for i in list if i not in gender_pronouns] for list in no_punctuation]\n",
    "    \n",
    "    #Stem\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "    stem = [[snow.stem(i) for i in list] for list in no_gender]\n",
    "    \n",
    "    #Combine words into single comment\n",
    "    cleanText = [\" \".join(i) for i in stem] \n",
    "    \n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean and isolate evaluations and ratings\n",
    "evaluations = clean(rmp.column(\"Comment\"))\n",
    "ratings = rmp.column(\"Rating_Type\")\n",
    "\n",
    "#Shuffle data\n",
    "evaluations, ratings = shuffle(evaluations, ratings, random_state=1)\n",
    "\n",
    "#Split data into training and testing\n",
    "evalTrain, evalTest, rateTrain, rateTest = train_test_split(evaluations, ratings, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the classifier\n",
    "\n",
    "#Tfidf values\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(evaluations)\n",
    "evalTrain = tfidf.transform(evalTrain)\n",
    "evalTest = tfidf.transform(evalTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59363636363636363"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logit model\n",
    "logit = LogisticRegression()\n",
    "logit.fit(evalTrain, rateTrain)\n",
    "logit.score(evalTest, rateTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness outcomes: logit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53454545454545455"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-nearest neighbor model \n",
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(evalTrain, rateTrain)\n",
    "KNN.score(evalTest, rateTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness outcomes: KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53272727272727272"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support vector machine model \n",
    "svm = svm.SVC()\n",
    "svm.fit(evalTrain, rateTrain)\n",
    "svm.score(evalTest, rateTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness outcomes: SVM model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
